{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a7dd710",
   "metadata": {},
   "source": [
    "# Pytorch Basics\n",
    "\n",
    "This notebook provides a brief introduction to PyTorch, a popular deep learning framework. It covers the basics of tensors, operations, and autograd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf68644c",
   "metadata": {},
   "source": [
    "## 1. Tensors\n",
    "Tensors are the fundamental data structure in PyTorch, similar to NumPy arrays but with additional capabilities for GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13fffe70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1608,  0.0503,  0.2296, -0.5242, -0.5071, -0.5347, -0.1495,\n",
       "           -0.2143,  0.0586, -0.5579,  0.4634,  0.0396,  0.4278,  0.5638,\n",
       "            0.1658,  0.3157,  0.0912, -0.2146,  0.3339,  0.1416],\n",
       "          [ 0.1470,  0.2288,  0.3112, -0.4854, -0.4598, -0.3597, -0.2195,\n",
       "           -0.2682,  0.0226, -0.7713,  0.5842,  0.1214,  0.5091,  0.4622,\n",
       "            0.0978,  0.4267,  0.1823, -0.0971, -0.0372,  0.1609],\n",
       "          [ 0.0776,  0.2778,  0.1839, -0.5647, -0.4277, -0.5484, -0.3234,\n",
       "           -0.3153, -0.0968, -0.7942,  0.6534,  0.2908,  0.4923,  0.5395,\n",
       "            0.0910,  0.5134,  0.0890, -0.3021,  0.0589,  0.1609],\n",
       "          [-0.0622,  0.1167,  0.2439, -0.4829, -0.4912, -0.5324, -0.2703,\n",
       "           -0.1726, -0.0855, -0.5913,  0.4466,  0.0980,  0.3151,  0.5187,\n",
       "            0.2010,  0.2519, -0.0937, -0.1522,  0.1076,  0.0319],\n",
       "          [ 0.2039,  0.0510,  0.1976, -0.5678, -0.4675, -0.4309, -0.0721,\n",
       "           -0.2550,  0.1348, -0.7566,  0.5934,  0.1021,  0.4247,  0.5799,\n",
       "            0.1164,  0.2898,  0.0674, -0.2169,  0.0624,  0.2657]],\n",
       " \n",
       "         [[-0.2737,  0.0309,  0.4621, -0.1506, -0.5896, -0.6965, -0.1675,\n",
       "           -0.2487, -0.3086, -0.7916,  0.0015,  0.3529,  0.0883,  0.6408,\n",
       "           -0.1150,  0.1833,  0.2784, -0.3247,  0.4130, -0.2532],\n",
       "          [-0.1120, -0.0388,  0.3126, -0.2854, -0.5927, -0.6517, -0.1661,\n",
       "           -0.4320, -0.2932, -0.8285,  0.0921,  0.3195,  0.2711,  0.6852,\n",
       "           -0.0854,  0.2570,  0.2355, -0.3473,  0.3136, -0.1448],\n",
       "          [-0.3190, -0.1495,  0.3849,  0.1103, -0.4707, -0.5574, -0.1439,\n",
       "           -0.2713, -0.4786, -0.7069, -0.1283,  0.1391,  0.3120,  0.2850,\n",
       "           -0.2775,  0.0095,  0.3760, -0.2207,  0.4494, -0.2011],\n",
       "          [-0.2691,  0.0033,  0.3587, -0.2128, -0.5432, -0.6480, -0.2045,\n",
       "           -0.2416, -0.4371, -0.7593,  0.1202,  0.2441,  0.4202,  0.4077,\n",
       "           -0.1419,  0.0590,  0.3562, -0.3511,  0.3520, -0.1074],\n",
       "          [-0.3697, -0.0216,  0.5074, -0.2191, -0.6411, -0.6405, -0.0634,\n",
       "           -0.2149, -0.3267, -0.8296, -0.0447,  0.3647,  0.1778,  0.6574,\n",
       "           -0.0750,  0.2284,  0.4450, -0.3225,  0.3888, -0.0980]],\n",
       " \n",
       "         [[-0.2327,  0.3624,  0.6078, -0.3146, -0.6828, -0.6045, -0.2354,\n",
       "           -0.3776, -0.3082, -0.6361,  0.1046, -0.0138,  0.5001,  0.0837,\n",
       "           -0.1566,  0.0879,  0.2894, -0.0630,  0.2470, -0.2413],\n",
       "          [-0.0659,  0.1647,  0.5809, -0.0127, -0.4695, -0.5684, -0.2399,\n",
       "           -0.3878, -0.1480, -0.5766,  0.0891, -0.0262,  0.2951,  0.2617,\n",
       "           -0.2760, -0.0357,  0.2321,  0.0056,  0.3339, -0.5079],\n",
       "          [-0.0056,  0.4114,  0.5171, -0.4183, -0.5915, -0.5646, -0.2800,\n",
       "           -0.3261, -0.2242, -0.6301,  0.3837,  0.1603,  0.4217,  0.2716,\n",
       "           -0.1810,  0.0327,  0.1426, -0.0794,  0.1016, -0.3779],\n",
       "          [ 0.3877,  0.0087,  0.5174, -0.2508, -0.6007, -0.6524,  0.0372,\n",
       "           -0.3336, -0.0077, -0.6724,  0.2221, -0.0431,  0.4205,  0.5071,\n",
       "           -0.3705, -0.0178,  0.4088, -0.2983,  0.3228, -0.3870],\n",
       "          [-0.0585,  0.3114,  0.6119, -0.3950, -0.6747, -0.5991, -0.1047,\n",
       "           -0.4078, -0.1872, -0.6511,  0.0992, -0.0422,  0.5309,  0.1997,\n",
       "           -0.1858,  0.1156,  0.4666, -0.0823,  0.3850, -0.1840]]],\n",
       "        grad_fn=<StackBackward0>),\n",
       " torch.Size([1, 5, 20]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Our input tensor\n",
    "inputs = torch.rand(3, 5, 10)\n",
    "\n",
    "# Our RNN layer\n",
    "rnn_layer = nn.RNN(input_size=10, hidden_size=20)\n",
    "output, hidden = rnn_layer(inputs)\n",
    "output, hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218ebe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch and other necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check PyTorch version and CUDA availability\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fdcf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tensors from different sources\n",
    "\n",
    "# From Python lists\n",
    "tensor_from_list = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(\"Tensor from list:\", tensor_from_list)\n",
    "\n",
    "# From NumPy arrays\n",
    "numpy_array = np.array([1.0, 2.0, 3.0])\n",
    "tensor_from_numpy = torch.from_numpy(numpy_array)\n",
    "print(\"Tensor from NumPy:\", tensor_from_numpy)\n",
    "\n",
    "# Creating specific types of tensors\n",
    "zeros_tensor = torch.zeros(3, 4)  # 3x4 tensor of zeros\n",
    "ones_tensor = torch.ones(2, 3)    # 2x3 tensor of ones\n",
    "random_tensor = torch.randn(2, 3) # 2x3 tensor with random values from normal distribution\n",
    "range_tensor = torch.arange(0, 10, 2)  # tensor with values [0, 2, 4, 6, 8]\n",
    "\n",
    "print(\"\\nZeros tensor:\\n\", zeros_tensor)\n",
    "print(\"\\nOnes tensor:\\n\", ones_tensor)\n",
    "print(\"\\nRandom tensor:\\n\", random_tensor)\n",
    "print(\"\\nRange tensor:\", range_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fde680",
   "metadata": {},
   "source": [
    "### Tensor Properties\n",
    "Every tensor has important properties that define its structure and data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9b04d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring tensor properties\n",
    "example_tensor = torch.randn(3, 4, 5)\n",
    "\n",
    "print(\"Tensor:\", example_tensor)\n",
    "print(\"\\nShape (size):\", example_tensor.shape)\n",
    "print(\"Data type:\", example_tensor.dtype)\n",
    "print(\"Device:\", example_tensor.device)\n",
    "print(\"Number of dimensions:\", example_tensor.ndim)\n",
    "print(\"Number of elements:\", example_tensor.numel())\n",
    "\n",
    "# Changing data types\n",
    "float_tensor = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "int_tensor = float_tensor.int()\n",
    "double_tensor = float_tensor.double()\n",
    "\n",
    "print(f\"\\nOriginal (float32): {float_tensor} - dtype: {float_tensor.dtype}\")\n",
    "print(f\"Converted to int: {int_tensor} - dtype: {int_tensor.dtype}\")\n",
    "print(f\"Converted to double: {double_tensor} - dtype: {double_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5cd4ad",
   "metadata": {},
   "source": [
    "## 2. Tensor Operations\n",
    "PyTorch provides a wide range of operations for tensors, including mathematical operations, indexing, and reshaping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f009a17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic arithmetic operations\n",
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "y = torch.tensor([4.0, 5.0, 6.0])\n",
    "\n",
    "# Addition\n",
    "addition = x + y\n",
    "addition_method = torch.add(x, y)\n",
    "print(\"Addition:\", addition)\n",
    "print(\"Addition (method):\", addition_method)\n",
    "\n",
    "# Subtraction\n",
    "subtraction = x - y\n",
    "print(\"Subtraction:\", subtraction)\n",
    "\n",
    "# Multiplication (element-wise)\n",
    "multiplication = x * y\n",
    "print(\"Element-wise multiplication:\", multiplication)\n",
    "\n",
    "# Division\n",
    "division = y / x\n",
    "print(\"Division:\", division)\n",
    "\n",
    "# Matrix multiplication\n",
    "matrix_a = torch.randn(2, 3)\n",
    "matrix_b = torch.randn(3, 4)\n",
    "matrix_mult = torch.mm(matrix_a, matrix_b)  # or matrix_a @ matrix_b\n",
    "print(f\"\\nMatrix A shape: {matrix_a.shape}\")\n",
    "print(f\"Matrix B shape: {matrix_b.shape}\")\n",
    "print(f\"Matrix multiplication result shape: {matrix_mult.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ef2fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor reshaping and indexing\n",
    "original_tensor = torch.arange(12).float()\n",
    "print(\"Original tensor:\", original_tensor)\n",
    "\n",
    "# Reshaping\n",
    "reshaped_2d = original_tensor.view(3, 4)  # Reshape to 3x4\n",
    "reshaped_3d = original_tensor.view(2, 2, 3)  # Reshape to 2x2x3\n",
    "print(\"\\nReshaped to 3x4:\\n\", reshaped_2d)\n",
    "print(\"\\nReshaped to 2x2x3:\\n\", reshaped_3d)\n",
    "\n",
    "# Indexing and slicing\n",
    "matrix = torch.randn(4, 5)\n",
    "print(\"\\nOriginal matrix:\\n\", matrix)\n",
    "\n",
    "# Access specific elements\n",
    "print(\"Element at [1, 2]:\", matrix[1, 2])\n",
    "print(\"First row:\", matrix[0, :])\n",
    "print(\"First column:\", matrix[:, 0])\n",
    "print(\"Sub-matrix [1:3, 2:4]:\\n\", matrix[1:3, 2:4])\n",
    "\n",
    "# Advanced indexing\n",
    "indices = torch.tensor([0, 2])\n",
    "selected_rows = matrix[indices]\n",
    "print(\"\\nSelected rows (0 and 2):\\n\", selected_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f86077",
   "metadata": {},
   "source": [
    "## 3. Autograd - Automatic Differentiation\n",
    "PyTorch's autograd system automatically computes gradients, which is essential for training neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bdeee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autograd basics\n",
    "# Create tensors with gradient tracking enabled\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "# Define a function\n",
    "z = x**2 + y**3\n",
    "print(\"z =\", z)\n",
    "\n",
    "# Compute gradients\n",
    "z.backward()\n",
    "\n",
    "# Access gradients\n",
    "print(\"dz/dx =\", x.grad)  # Should be 2*x = 4\n",
    "print(\"dz/dy =\", y.grad)  # Should be 3*y^2 = 27\n",
    "\n",
    "# More complex example with multiple operations\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "print(\"\\nInput tensor x:\", x)\n",
    "\n",
    "y = x * 2\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(\"Output:\", out)\n",
    "\n",
    "# Compute gradients\n",
    "out.backward()\n",
    "print(\"Gradients:\", x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b67023",
   "metadata": {},
   "source": [
    "## 4. Neural Networks with torch.nn\n",
    "PyTorch provides the `torch.nn` module for building neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e527a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create a model instance\n",
    "model = SimpleNN(input_size=10, hidden_size=20, output_size=1)\n",
    "print(\"Model architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Model parameters\n",
    "print(\"\\nModel parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.shape}\")\n",
    "\n",
    "# Forward pass example\n",
    "input_data = torch.randn(5, 10)  # Batch of 5 samples, each with 10 features\n",
    "output = model(input_data)\n",
    "print(f\"\\nInput shape: {input_data.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752325ca",
   "metadata": {},
   "source": [
    "## 5. Training a Simple Model\n",
    "Let's create a simple training loop to demonstrate how to train a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65a3f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data for a simple regression problem\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "\n",
    "# Create synthetic data: y = 2*x + 1 + noise\n",
    "n_samples = 100\n",
    "x_data = torch.randn(n_samples, 1)\n",
    "y_data = 2 * x_data + 1 + 0.1 * torch.randn(n_samples, 1)\n",
    "\n",
    "print(f\"Input data shape: {x_data.shape}\")\n",
    "print(f\"Target data shape: {y_data.shape}\")\n",
    "\n",
    "# Create a simple linear model\n",
    "model = nn.Linear(1, 1)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "losses = []\n",
    "num_epochs = 100\n",
    "\n",
    "print(\"Training started...\")\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()  # Clear gradients\n",
    "    loss.backward()        # Compute gradients\n",
    "    optimizer.step()       # Update parameters\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Final model parameters\n",
    "print(f\"\\nTrained parameters:\")\n",
    "print(f\"Weight: {model.weight.item():.4f} (should be close to 2.0)\")\n",
    "print(f\"Bias: {model.bias.item():.4f} (should be close to 1.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot 1: Training loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot 2: Data and fitted line\n",
    "plt.subplot(1, 2, 2)\n",
    "with torch.no_grad():\n",
    "    # Generate predictions for plotting\n",
    "    x_plot = torch.linspace(-3, 3, 100).unsqueeze(1)\n",
    "    y_plot = model(x_plot)\n",
    "    \n",
    "    plt.scatter(x_data.numpy(), y_data.numpy(), alpha=0.5, label='Data')\n",
    "    plt.plot(x_plot.numpy(), y_plot.numpy(), 'r-', label='Fitted line')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Linear Regression Results')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b83363",
   "metadata": {},
   "source": [
    "## 6. GPU Usage\n",
    "PyTorch makes it easy to use GPUs for accelerated computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c27000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU operations\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create tensors on GPU (if available)\n",
    "if torch.cuda.is_available():\n",
    "    # Create tensor directly on GPU\n",
    "    gpu_tensor = torch.randn(3, 3, device=device)\n",
    "    print(\"Tensor on GPU:\", gpu_tensor.device)\n",
    "    \n",
    "    # Move tensor from CPU to GPU\n",
    "    cpu_tensor = torch.randn(3, 3)\n",
    "    gpu_tensor2 = cpu_tensor.to(device)\n",
    "    print(\"Moved tensor device:\", gpu_tensor2.device)\n",
    "    \n",
    "    # Operations on GPU\n",
    "    result = gpu_tensor + gpu_tensor2\n",
    "    print(\"Result device:\", result.device)\n",
    "    \n",
    "    # Move back to CPU for numpy conversion\n",
    "    cpu_result = result.cpu()\n",
    "    print(\"CPU result shape:\", cpu_result.shape)\n",
    "else:\n",
    "    print(\"CUDA not available. Using CPU for all operations.\")\n",
    "    cpu_tensor = torch.randn(3, 3)\n",
    "    print(\"CPU tensor device:\", cpu_tensor.device)\n",
    "\n",
    "# Moving models to GPU\n",
    "model_example = nn.Linear(10, 1)\n",
    "model_example = model_example.to(device)\n",
    "print(f\"Model is on: {next(model_example.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f20fc0",
   "metadata": {},
   "source": [
    "## 7. Summary and Next Steps\n",
    "\n",
    "Congratulations! You've learned the basics of PyTorch:\n",
    "\n",
    "1. **Tensors**: The fundamental data structure in PyTorch\n",
    "2. **Operations**: Mathematical operations, reshaping, and indexing\n",
    "3. **Autograd**: Automatic differentiation for gradient computation\n",
    "4. **Neural Networks**: Building models with `torch.nn`\n",
    "5. **Training**: Complete training loops with loss functions and optimizers\n",
    "6. **GPU Usage**: Accelerating computations with CUDA\n",
    "\n",
    "### Next Steps:\n",
    "- Explore more complex neural network architectures (CNNs, RNNs)\n",
    "- Learn about different loss functions and optimizers\n",
    "- Work with real datasets using `torch.utils.data`\n",
    "- Implement more advanced training techniques (regularization, learning rate scheduling)\n",
    "- Explore PyTorch's ecosystem (torchvision, torchtext, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
