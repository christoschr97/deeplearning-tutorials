{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a10d403",
   "metadata": {},
   "source": [
    "# Graph Neural Networks with PyTorch Geometric (PyG)\n",
    "\n",
    "This tutorial walks through building a simple Graph Convolutional Network (GCN) for node classification on the Cora citation network using PyTorch Geometric. You'll learn to:\n",
    "\n",
    "- Represent graphs with `torch_geometric.data.Data`\n",
    "- Build a GCN with `torch_geometric.nn.GCNConv`\n",
    "- Train with train/val/test masks (Planetoid split)\n",
    "- Compute masked accuracy and evaluate the model\n",
    "\n",
    "Prerequisites: Basic PyTorch, tensors, and neural network training loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54d2380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badc53fc",
   "metadata": {},
   "source": [
    "This cell imports PyTorch and PyTorch Geometric modules we'll use:\n",
    "- `torch` for tensors and training utilities\n",
    "- `torch.nn.functional as F` for activation functions\n",
    "- `GCNConv` for the graph convolution layers\n",
    "- `Data` to hold graph structures (`x` and `edge_index`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491de9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # pick GPU if available, else CPU\n",
    "print(f\"PyTorch: {torch.__version__}\")  # print PyTorch version\n",
    "print(f\"Using device: {device}\")  # confirm which device we'll use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68837570",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de434f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[4, 2], edge_index=[2, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features = torch.tensor([[-1.0, 1.0],  # Node 0 features\n",
    "                               [0.0, 1.0],   # Node 1 features\n",
    "                               [1.0, 1.0],   # Node 2 features\n",
    "                               [1.0, -1.0]], # Node 3 features\n",
    "                              dtype=torch.float)\n",
    "\n",
    "edge_index = torch.tensor([[0, 0, 1, 2, 3],  # sources\n",
    "                           [1, 2, 2, 3, 0]], # targets\n",
    "                          dtype=torch.long)\n",
    "\n",
    "graph_data = Data(x=node_features, edge_index=edge_index)\n",
    "graph_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec6df6d",
   "metadata": {},
   "source": [
    "A simple example on how to create a simple GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba88234",
   "metadata": {},
   "source": [
    "## 2. A Tiny Graph Example\n",
    "We start with a toy graph to see how `Data(x, edge_index)` represents a graph in PyG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd269c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGNN(torch.nn.Module):\n",
    "  def __init__(self, num_features, num_classes):\n",
    "    super().__init__()\n",
    "    self.conv1 = GCNConv(in_channels=num_features, out_channels=16)  # first GCN layer\n",
    "    self.conv2 = GCNConv(in_channels=16, out_channels=num_classes)   # output layer -> num_classes\n",
    "\n",
    "  def forward(self, data):\n",
    "    x, edge_index = data.x, data.edge_index  # node features and graph edges\n",
    "    x = self.conv1(x, edge_index)            # message passing layer\n",
    "    x = F.relu(x)                             # non-linearity\n",
    "    x = self.conv2(x, edge_index)            # logits per class\n",
    "    x = F.log_softmax(x, dim=1)              # log-probs for NLLLoss\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30745015",
   "metadata": {},
   "source": [
    "## 3. Dataset: Cora (Planetoid)\n",
    "We'll use the Cora citation network from the Planetoid benchmark. The dataset provides node features, labels, and train/val/test masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e41b6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')  # download/cache Cora under /tmp/Cora\n",
    "\n",
    "data = dataset[0].to(device)  # single graph -> move to device\n",
    "print(data)  # quick overview of tensors and masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3709e2",
   "metadata": {},
   "source": [
    "This cell downloads and loads the Cora dataset:\n",
    "- `root` controls the cache folder (change to a persistent path if you want it saved)\n",
    "- `dataset[0]` returns the single `Data` graph with features, labels, and masks\n",
    "- We move `data` to the selected device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d4d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1433, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_node_features, dataset.num_classes, data.x.shape, data.edge_index.shape, data.y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8770c2a2",
   "metadata": {},
   "source": [
    "Quick sanity-check on shapes:\n",
    "- `num_node_features` and `num_classes` from the dataset\n",
    "- `x` (#nodes, #features), `edge_index` (2, #edges), `y` (#nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88094be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleGNN(num_features=dataset.num_node_features, num_classes=dataset.num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "loss_fn = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0791f10f",
   "metadata": {},
   "source": [
    "Instantiate the model and training utilities:\n",
    "- `SimpleGNN` with two GCN layers\n",
    "- `Adam` optimizer with a small L2 (`weight_decay`)\n",
    "- `NLLLoss` because the model returns log-probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9838e0a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9413, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(data)\n",
    "y_true = data.y\n",
    "print(y_pred.shape, y_true.shape)\n",
    "loss_fn(y_pred[data.train_mask], y_true[data.train_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c4262c",
   "metadata": {},
   "source": [
    "First forward pass to verify shapes and the training loss on the training nodes (using the mask)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6ad2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2708"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.train_mask)  # number of nodes in the training split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b379e0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred[dataset.train_mask])  # same number of predictions as training nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0e862d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationModule(name: \"accuracy\", module_type: \"metric\", features: {'predictions': Value('int32'), 'references': Value('int32')}, usage: \"\"\"\n",
       "Args:\n",
       "    predictions (`list` of `int`): Predicted labels.\n",
       "    references (`list` of `int`): Ground truth labels.\n",
       "    normalize (`boolean`): If set to False, returns the number of correctly classified samples. Otherwise, returns the fraction of correctly classified samples. Defaults to True.\n",
       "    sample_weight (`list` of `float`): Sample weights Defaults to None.\n",
       "\n",
       "Returns:\n",
       "    accuracy (`float` or `int`): Accuracy score. Minimum possible value is 0. Maximum possible value is 1.0, or the number of examples input, if `normalize` is set to `True`.. A higher score means higher accuracy.\n",
       "\n",
       "Examples:\n",
       "\n",
       "    Example 1-A simple example\n",
       "        >>> accuracy_metric = evaluate.load(\"accuracy\")\n",
       "        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0])\n",
       "        >>> print(results)\n",
       "        {'accuracy': 0.5}\n",
       "\n",
       "    Example 2-The same as Example 1, except with `normalize` set to `False`.\n",
       "        >>> accuracy_metric = evaluate.load(\"accuracy\")\n",
       "        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], normalize=False)\n",
       "        >>> print(results)\n",
       "        {'accuracy': 3.0}\n",
       "\n",
       "    Example 3-The same as Example 1, except with `sample_weight` set.\n",
       "        >>> accuracy_metric = evaluate.load(\"accuracy\")\n",
       "        >>> results = accuracy_metric.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], sample_weight=[0.5, 2, 0.7, 0.5, 9, 0.4])\n",
       "        >>> print(results)\n",
       "        {'accuracy': 0.8778625954198473}\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def masked_accuracy(logits, y, mask):\n",
    "    preds = logits.argmax(dim=1)\n",
    "    correct = (preds[mask] == y[mask]).sum()\n",
    "    return (correct.float() / mask.sum()).item()\n",
    "\n",
    "masked_accuracy(model(data), data.y, data.train_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0eb8f1",
   "metadata": {},
   "source": [
    "Utility to compute accuracy on a subset of nodes defined by a boolean mask (train/val/test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a80bacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss = 1.9413\n",
      "Accuracy: {'accuracy': 0.404}\n",
      "Epoch 010: Loss = 0.6166\n",
      "Accuracy: {'accuracy': 0.726}\n",
      "Epoch 020: Loss = 0.1024\n",
      "Accuracy: {'accuracy': 0.768}\n",
      "Epoch 030: Loss = 0.0211\n",
      "Accuracy: {'accuracy': 0.756}\n",
      "Epoch 040: Loss = 0.0076\n",
      "Accuracy: {'accuracy': 0.75}\n",
      "Epoch 050: Loss = 0.0042\n",
      "Accuracy: {'accuracy': 0.75}\n",
      "Epoch 060: Loss = 0.0030\n",
      "Accuracy: {'accuracy': 0.75}\n",
      "Epoch 070: Loss = 0.0024\n",
      "Accuracy: {'accuracy': 0.746}\n",
      "Epoch 080: Loss = 0.0021\n",
      "Accuracy: {'accuracy': 0.744}\n",
      "Epoch 090: Loss = 0.0018\n",
      "Accuracy: {'accuracy': 0.744}\n",
      "Epoch 100: Loss = 0.0016\n",
      "Accuracy: {'accuracy': 0.744}\n",
      "Epoch 110: Loss = 0.0015\n",
      "Accuracy: {'accuracy': 0.744}\n",
      "Epoch 120: Loss = 0.0013\n",
      "Accuracy: {'accuracy': 0.746}\n",
      "Epoch 130: Loss = 0.0012\n",
      "Accuracy: {'accuracy': 0.746}\n",
      "Epoch 140: Loss = 0.0011\n",
      "Accuracy: {'accuracy': 0.746}\n",
      "Epoch 150: Loss = 0.0010\n",
      "Accuracy: {'accuracy': 0.746}\n",
      "Epoch 160: Loss = 0.0010\n",
      "Accuracy: {'accuracy': 0.746}\n",
      "Epoch 170: Loss = 0.0009\n",
      "Accuracy: {'accuracy': 0.746}\n",
      "Epoch 180: Loss = 0.0008\n",
      "Accuracy: {'accuracy': 0.746}\n",
      "Epoch 190: Loss = 0.0008\n",
      "Accuracy: {'accuracy': 0.746}\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):\n",
    "  model.train()\n",
    "  logits = model(data)  # forward pass\n",
    "  loss = loss_fn(logits[data.train_mask], data.y[data.train_mask])  # compute loss on train nodes\n",
    "  optimizer.zero_grad()  # reset gradients\n",
    "  loss.backward()  # backprop\n",
    "  optimizer.step()  # update weights\n",
    "\n",
    "  if epoch % 10 == 0:  # log every 10 epochs\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "      logits = model(data)  # recompute logits without grad\n",
    "      train_acc = masked_accuracy(logits, data.y, data.train_mask)  # train accuracy\n",
    "      val_acc = masked_accuracy(logits, data.y, data.val_mask)  # val accuracy\n",
    "    print(f'Epoch {epoch:03d}: Loss={loss.item():.4f} | Train Acc={train_acc:.3f} | Val Acc={val_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce63d71",
   "metadata": {},
   "source": [
    "Training loop:\n",
    "- Forward pass on all nodes, compute NLL loss on training nodes only\n",
    "- Backprop and optimizer step\n",
    "- Every few epochs, compute accuracy on train/val masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2802e1",
   "metadata": {},
   "source": [
    "## 4. Evaluation on Test Split\n",
    "After training, evaluate the model on the held-out test nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f3f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    logits = model(data)\n",
    "    test_acc = masked_accuracy(logits, data.y, data.test_mask)\n",
    "print({\"test_accuracy\": round(test_acc, 4)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdf99c5",
   "metadata": {},
   "source": [
    "Finally, evaluate accuracy on the held-out test nodes to report the result you'd publish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5daac03",
   "metadata": {},
   "source": [
    "## 5. Notes and References\n",
    "\n",
    "- Loss: We used `NLLLoss` with `log_softmax` outputs. Alternatively, output raw logits and use `CrossEntropyLoss`.\n",
    "- Masks: `train_mask`, `val_mask`, `test_mask` are boolean vectors that select nodes for each split.\n",
    "- Device: We moved both the data object and model to the selected device.\n",
    "\n",
    "References:\n",
    "- PyTorch Geometric docs: https://pytorch-geometric.readthedocs.io/\n",
    "- GCN paper: https://arxiv.org/abs/1609.02907"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
