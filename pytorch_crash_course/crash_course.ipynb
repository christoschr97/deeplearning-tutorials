{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af29ce98",
   "metadata": {},
   "source": [
    "# PyTorch Crash Course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d5a7b5",
   "metadata": {},
   "source": [
    "## 5 Chapters\n",
    "1. Introduction to Tensors  \n",
    "  - Tensor Operations: Create, Numpy, GPU Support\n",
    "2. Autograd: Automatic Differentiation of PyTorch  \n",
    "  - Linear Regression Example\n",
    "3. Training Loop with: Model, Loss, Optimizer  \n",
    "  - A Typical PyTorch Workflow / training pipeline\n",
    "4. Neural Network  \n",
    "  - Also: GPU/Mps, DataLoader, Transforms & Evaluation\n",
    "5. Convolutional Neural Network (CNN)  \n",
    "  - Also: Save & Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea253595",
   "metadata": {},
   "source": [
    "# 1. Introduction to Tensors\n",
    "\n",
    "Everything in Pytorch is a tensor. Tensor is the basic datastructure in PyTorch that extends numpy. \n",
    "\n",
    "In theory, tensor is a multi-dimensional matrix containing elements of the same data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c668033a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty(5): tensor([0., 0., 0., 0., 0.]) with shape torch.Size([5])\n",
      "empty(2,3): tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) with shape: torch.Size([2, 3])\n",
      "ones(1): tensor([1.]) with shape: torch.Size([1])\n",
      "ones(1,2): tensor([[1., 1.]]) with shape: torch.Size([1, 2])\n",
      "zeros(2): tensor([0., 0.]) with shape: torch.Size([2])\n",
      "zeros(2, 2): tensor([[0., 0.],\n",
      "        [0., 0.]]) with shape: torch.Size([2, 2])\n",
      "rand(5): tensor([0.6733, 0.4980, 0.4894, 0.5151, 0.1446]) with shape: torch.Size([5])\n",
      "rand(5,5): tensor([[0.8415, 0.5387, 0.5452, 0.6928, 0.3202],\n",
      "        [0.7853, 0.2013, 0.9171, 0.4358, 0.1147],\n",
      "        [0.9142, 0.1029, 0.1442, 0.8652, 0.0256],\n",
      "        [0.5981, 0.9496, 0.9197, 0.6694, 0.3403],\n",
      "        [0.4247, 0.6171, 0.0515, 0.8784, 0.1009]]) with shape: torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.empty(5)\n",
    "print(f'empty(5): {x} with shape {x.shape}')\n",
    "x = torch.empty(2,3)\n",
    "print(f'empty(2,3): {x} with shape: {x.shape}')\n",
    "x = torch.ones(1)\n",
    "print(f'ones(1): {x} with shape: {x.shape}')\n",
    "x = torch.ones(1,2)\n",
    "print(f'ones(1,2): {x} with shape: {x.shape}')\n",
    "x = torch.zeros(2)\n",
    "print(f'zeros(2): {x} with shape: {x.shape}')\n",
    "x = torch.zeros(2,2)\n",
    "print(f'zeros(2, 2): {x} with shape: {x.shape}')\n",
    "x = torch.rand(5)\n",
    "print(f'rand(5): {x} with shape: {x.shape}')\n",
    "x = torch.rand(5,5)\n",
    "print(f'rand(5,5): {x} with shape: {x.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a3d5c6",
   "metadata": {},
   "source": [
    "We can check the size of the tensor using `.size()` or the shape of a tensor using `.shape()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df8d6daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([5, 5])\n",
      "Shape: torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(f'Size: {x.size()}') # specific dimension .size(0)\n",
    "print(f'Shape: {x.shape}') # specific dimension .shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f8474ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensor tensor([[0.8415, 0.5387, 0.5452, 0.6928, 0.3202],\n",
      "        [0.7853, 0.2013, 0.9171, 0.4358, 0.1147],\n",
      "        [0.9142, 0.1029, 0.1442, 0.8652, 0.0256],\n",
      "        [0.5981, 0.9496, 0.9197, 0.6694, 0.3403],\n",
      "        [0.4247, 0.6171, 0.0515, 0.8784, 0.1009]]) has dtype: torch.float32\n",
      "The tensor tensor([[0.4570, 0.9282, 0.7173, 0.4727, 0.1353],\n",
      "        [0.1509, 0.6665, 0.3784, 0.6333, 0.7949],\n",
      "        [0.0498, 0.8657, 0.3813, 0.8369, 0.3643],\n",
      "        [0.0381, 0.1670, 0.9619, 0.4648, 0.5718],\n",
      "        [0.0898, 0.2207, 0.0068, 0.7817, 0.5752]], dtype=torch.float16) has dtype: torch.float16\n"
     ]
    }
   ],
   "source": [
    "# check the data type of a tensor using:\n",
    "print(f'The tensor {x} has dtype: {x.dtype}')\n",
    "\n",
    "# To define a tensor with different dtype we should define it upon creation\n",
    "x = torch.rand(5,5, dtype=torch.float16)\n",
    "print(f'The tensor {x} has dtype: {x.dtype}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6018ab3c",
   "metadata": {},
   "source": [
    "We can also construct a tensor from a Python List or a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da4d86f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np_array = np.array([1,2,3])\n",
    "x = torch.tensor(np_array)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b2c1783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_list = [1,2,3]\n",
    "x = torch.tensor(py_list)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1e09b6",
   "metadata": {},
   "source": [
    "Another one important thing to know is that a tensor has an argument `requires_grad` which is by default set to `False`. If we set this to true, then python will track `gradients` for that numpy array. \n",
    "\n",
    "In a simple way, it will tell pytorch that it will need to calculate gradients for this tensor. We need this later in the optimization step, and we use it for all variables in our model that we want to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0760287c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3], requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fab5502",
   "metadata": {},
   "source": [
    "## 1.2 Operations on tensors\n",
    "\n",
    "This is simliar to numpy arrays. All the operations unless specified are element-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5902b3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.]]),\n",
       " tensor([[0.9356, 0.8502],\n",
       "         [0.8692, 0.1311]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2,2)\n",
    "y = torch.rand(2,2)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca50c5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9356, 1.8502],\n",
       "        [1.8692, 1.1311]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elementwise addition\n",
    "z = x + y\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "457202af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtraction: tensor([[0.0644, 0.1498],\n",
      "        [0.1308, 0.8689]])\n",
      "subtraction: tensor([[0.9356, 0.8502],\n",
      "        [0.8692, 0.1311]])\n",
      "subtraction: tensor([[1.0688, 1.1762],\n",
      "        [1.1505, 7.6269]])\n"
     ]
    }
   ],
   "source": [
    "# Elementwise subtraction, multiplication and division\n",
    "z = x - y\n",
    "print(f'subtraction: {z}')\n",
    "z = x * y\n",
    "print(f'subtraction: {z}')\n",
    "z = x / y\n",
    "print(f'subtraction: {z}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d480327",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991e37ec",
   "metadata": {},
   "source": [
    "Indexing and slicing on torch tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "decbc6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3224, 0.0053],\n",
       "         [0.7883, 0.4331],\n",
       "         [0.2507, 0.8969]],\n",
       "\n",
       "        [[0.2828, 0.5628],\n",
       "         [0.0871, 0.4265],\n",
       "         [0.2292, 0.5341]],\n",
       "\n",
       "        [[0.4714, 0.1922],\n",
       "         [0.1939, 0.3335],\n",
       "         [0.3064, 0.5884]],\n",
       "\n",
       "        [[0.9674, 0.1169],\n",
       "         [0.5641, 0.1002],\n",
       "         [0.3880, 0.6121]],\n",
       "\n",
       "        [[0.6654, 0.0183],\n",
       "         [0.9934, 0.4897],\n",
       "         [0.2130, 0.9235]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5,3,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f2ca86a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7883, 0.4331],\n",
       "        [0.0871, 0.4265],\n",
       "        [0.1939, 0.3335],\n",
       "        [0.5641, 0.1002],\n",
       "        [0.9934, 0.4897]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071d941e",
   "metadata": {},
   "source": [
    "`.item()` converts a single number tensor into scalar. If it has more than 1 element it will break."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c7fd885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype: 0.4265291690826416 of tensor tensor([[[0.3224, 0.0053],\n",
      "         [0.7883, 0.4331],\n",
      "         [0.2507, 0.8969]],\n",
      "\n",
      "        [[0.2828, 0.5628],\n",
      "         [0.0871, 0.4265],\n",
      "         [0.2292, 0.5341]],\n",
      "\n",
      "        [[0.4714, 0.1922],\n",
      "         [0.1939, 0.3335],\n",
      "         [0.3064, 0.5884]],\n",
      "\n",
      "        [[0.9674, 0.1169],\n",
      "         [0.5641, 0.1002],\n",
      "         [0.3880, 0.6121]],\n",
      "\n",
      "        [[0.6654, 0.0183],\n",
      "         [0.9934, 0.4897],\n",
      "         [0.2130, 0.9235]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4265291690826416, float)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wihtout item it is a tensor:\n",
    "print(f'dtype: {x[1,1,1]} of tensor {x}')\n",
    "x[1,1,1].item(), type(x[1,1,1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d24aec92",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 2 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: a Tensor with 2 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "x[1,1].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f54333",
   "metadata": {},
   "source": [
    "Reshaping a tensor:\n",
    "- Can be done either with `view()` either with `.reshape()`\n",
    "\n",
    "The main differences between torch.view() and torch.reshape() are: Memory and Storage\n",
    "\n",
    "`view()`:\n",
    "- Creates a view of the original tensor (shares the same memory)\n",
    "- Does not copy data - just changes how the tensor is interpreted\n",
    "- Requires the tensor to be contiguous in memory\n",
    "- Will fail if the tensor is not contiguous\n",
    "\n",
    "`reshape()`:\n",
    "- Can return either a view OR a copy depending on the tensor's memory layout\n",
    "- Works with both contiguous and non-contiguous tensors\n",
    "- May create a copy if the tensor is not contiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a4bf0393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7304, 0.0771, 0.7171, 0.3782, 0.4496, 0.0919, 0.6032, 0.2691, 0.3198,\n",
       "         0.6993, 0.6584, 0.2737, 0.7963, 0.5940, 0.6395, 0.0698]),\n",
       " torch.Size([16]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(4,4)\n",
    "y = x.view(16)\n",
    "y, x.view(16).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "508482f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7304, 0.0771, 0.7171, 0.3782, 0.4496, 0.0919, 0.6032, 0.2691],\n",
       "        [0.3198, 0.6993, 0.6584, 0.2737, 0.7963, 0.5940, 0.6395, 0.0698]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(-1, 8) # will fill the dimensions required to match the shape of the original tensor\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0965337b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x storage address: 5409951936\n",
      "z storage address: 5409951936\n"
     ]
    }
   ],
   "source": [
    "print(f\"x storage address: {x.storage().data_ptr()}\")\n",
    "print(f\"z storage address: {z.storage().data_ptr()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f03c57",
   "metadata": {},
   "source": [
    "Convert a tensor to a numpy array or vice versa.\n",
    "\n",
    "If tensors are on the CPU, converting them to numpy will share the same memory location (so one change affect the both the tensor and the numpy array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5478269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5,2)\n",
    "np_x = x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "733b7597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4628, 1.5563],\n",
      "        [1.7423, 1.0034],\n",
      "        [1.6913, 1.0113],\n",
      "        [1.0346, 1.1374],\n",
      "        [1.0591, 1.0742]])\n",
      "[[1.462799  1.5562607]\n",
      " [1.7423112 1.003419 ]\n",
      " [1.691334  1.0113358]\n",
      " [1.0345505 1.137443 ]\n",
      " [1.0590763 1.0742233]]\n"
     ]
    }
   ],
   "source": [
    "x.add_(1)\n",
    "print(x)\n",
    "print(np_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8443ee6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x == np_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ca1f23",
   "metadata": {},
   "source": [
    "On the other hand, if we create a torch from numpy will still share the same memory address, unless we specify explicitly a new tensor from that numpy array with the traditional way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee2582c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: torch.from_numpy() - SHARES memory\n",
    "tensor1 = torch.from_numpy(np_array)\n",
    "\n",
    "# Method 2: torch.tensor() - COPIES data (creates new memory)\n",
    "tensor2 = torch.tensor(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f3092496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original numpy: [1 2 3]\n",
      "tensor1 (from_numpy): tensor([1, 2, 3])\n",
      "tensor2 (tensor): tensor([1, 2, 3])\n",
      "\n",
      "After modifying numpy array:\n",
      "Original numpy: [999   2   3]\n",
      "tensor1 (from_numpy): tensor([999,   2,   3])\n",
      "tensor2 (tensor): tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Test memory sharing\n",
    "print(\"Original numpy:\", np_array)\n",
    "print(\"tensor1 (from_numpy):\", tensor1)\n",
    "print(\"tensor2 (tensor):\", tensor2)\n",
    "\n",
    "# Modify the original numpy array\n",
    "np_array[0] = 999\n",
    "\n",
    "print(\"\\nAfter modifying numpy array:\")\n",
    "print(\"Original numpy:\", np_array)\n",
    "print(\"tensor1 (from_numpy):\", tensor1)  # Will change!\n",
    "print(\"tensor2 (tensor):\", tensor2)      # Won't change!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c8dc68",
   "metadata": {},
   "source": [
    "## 1.3 GPU Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c8123d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%writefile ../utils/device.py\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "30e21a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps:0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x = x.to('mps')  \n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a822bc27",
   "metadata": {},
   "source": [
    "If you know you will need a tensor to specific device, you can specify it upon initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "761e1f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3], device=device)\n",
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f5a92d",
   "metadata": {},
   "source": [
    "# Autograd\n",
    "\n",
    "Automatic Differentiation Engine (Autograd) of PyTorch is the system that automatically computes derivatives using chain rule.\n",
    "\n",
    "In order to track any operations we do on any tensor, which we will need later in order to calculate the gradients (derivatives on hyperdimensional space). So to achieve this we need to set the attribute `requires_grad=True`.\n",
    "\n",
    "Setting `requires_grad=True` on a tensor tells PyTorch to track operations on it and build the computation graph so you can compute gradients via .backward()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7aac9e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7203, 0.2642, 2.0011], requires_grad=True)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9829b3c",
   "metadata": {},
   "source": [
    "If we print y bellow after we do an operation to it, it will have the attribute grad_fn.\n",
    "\n",
    "This function is what will be used afterwards when we calculate gradients. So we do calculations in a forward direction and then go in a backward direction and calculate the gradients.\n",
    "\n",
    "You can also see that the backward function is different if we add or multiply or any other operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "70606b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.7203, 2.2642, 4.0011], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x + 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507acabd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.6586, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y * y\n",
    "# z = z.mean()\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54bea8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before we call backwards: None\n",
      "After we triggered backwards on the end result: tensor([2.4802, 1.5094, 2.6674])\n"
     ]
    }
   ],
   "source": [
    "print(f'Before we call backwards: {x.grad}')\n",
    "z.backward() # dz/dx\n",
    "print(f'After we triggered backwards on the end result: {x.grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686e9b82",
   "metadata": {},
   "source": [
    "`Note`\n",
    "\n",
    "Calling `.backward()` accumulates on existing gradients, so when we do a training loop we need to zero the gradients before we trigger backward again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c33635",
   "metadata": {},
   "source": [
    "How to stop tensors to track gradients?\n",
    "\n",
    "e.g\n",
    "- When we eval a model\n",
    "- When we update our weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dd19eae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# requires_grad=False\n",
    "x.requires_grad_(False)\n",
    "\n",
    "# x.detach(): creates a new tensor with requires_grad = False\n",
    "a = torch.rand(2,3, requires_grad=True)\n",
    "b = a.detach()\n",
    "b.requires_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "04c740c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "b = torch.randn(2,3, requires_grad=True)\n",
    "\n",
    "print(b.requires_grad)\n",
    "# wrap with torch.no_grad():\n",
    "with torch.no_grad():\n",
    "  b = b ** 5\n",
    "  print(b.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0706db",
   "metadata": {},
   "source": [
    "# Linear Regression with Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "dc351fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9cb8d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.tensor([1,2,3,4,5,6,7,8])\n",
    "Y = torch.tensor([2,4,6,8,10,12,14,16])\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "def forward(x):\n",
    "  return w*x\n",
    "  \n",
    "def loss_fn(y, predictions):\n",
    "  return ((predictions - y)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "21684f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 w(after)=1.020000\n",
      "\n",
      "Train Loss: 102.0\n",
      "Y Predictions: tensor([11.2200, 22.4400, 33.6600, 44.8800, 51.0000, 61.2000])\n",
      "Y Real: tensor([ 22,  44,  66,  88, 100, 120])\n",
      "Epoch 2 w(after)=1.519800\n",
      "\n",
      "Train Loss: 24.49020004272461\n",
      "Y Predictions: tensor([16.7178, 33.4356, 50.1534, 66.8712, 75.9900, 91.1880])\n",
      "Y Real: tensor([ 22,  44,  66,  88, 100, 120])\n",
      "Epoch 3 w(after)=1.764702\n",
      "\n",
      "Train Loss: 5.880098819732666\n",
      "Y Predictions: tensor([ 19.4117,  38.8234,  58.2352,  77.6469,  88.2351, 105.8821])\n",
      "Y Real: tensor([ 22,  44,  66,  88, 100, 120])\n",
      "Epoch 4 w(after)=1.884704\n",
      "\n",
      "Train Loss: 1.4118114709854126\n",
      "Y Predictions: tensor([ 20.7317,  41.4635,  62.1952,  82.9270,  94.2352, 113.0822])\n",
      "Y Real: tensor([ 22,  44,  66,  88, 100, 120])\n",
      "Epoch 5 w(after)=1.943505\n",
      "\n",
      "Train Loss: 0.33897578716278076\n",
      "Y Predictions: tensor([ 21.3786,  42.7571,  64.1357,  85.5142,  97.1752, 116.6103])\n",
      "Y Real: tensor([ 22,  44,  66,  88, 100, 120])\n",
      "Epoch 6 w(after)=1.972317\n",
      "\n",
      "Train Loss: 0.0813881903886795\n",
      "Y Predictions: tensor([ 21.6955,  43.3910,  65.0865,  86.7820,  98.6159, 118.3391])\n",
      "Y Real: tensor([ 22,  44,  66,  88, 100, 120])\n",
      "Epoch 7 w(after)=1.986436\n",
      "\n",
      "Train Loss: 0.019541269168257713\n",
      "Y Predictions: tensor([ 21.8508,  43.7016,  65.5524,  87.4032,  99.3218, 119.1861])\n",
      "Y Real: tensor([ 22,  44,  66,  88, 100, 120])\n",
      "Epoch 8 w(after)=1.993353\n",
      "\n",
      "Train Loss: 0.004691871348768473\n",
      "Y Predictions: tensor([ 21.9269,  43.8538,  65.7807,  87.7076,  99.6677, 119.6012])\n",
      "Y Real: tensor([ 22,  44,  66,  88, 100, 120])\n",
      "Epoch 9 w(after)=1.996743\n",
      "\n",
      "Train Loss: 0.0011265305802226067\n",
      "Y Predictions: tensor([ 21.9642,  43.9284,  65.8925,  87.8567,  99.8372, 119.8046])\n",
      "Y Real: tensor([ 22,  44,  66,  88, 100, 120])\n",
      "Epoch 10 w(after)=1.998404\n",
      "\n",
      "Train Loss: 0.0002704716462176293\n",
      "Y Predictions: tensor([ 21.9824,  43.9649,  65.9473,  87.9298,  99.9202, 119.9043])\n",
      "Y Real: tensor([ 22,  44,  66,  88, 100, 120])\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "epochs = 10\n",
    "\n",
    "X_test = torch.tensor([11,22,33,44,50,60])\n",
    "y_test = torch.tensor([22,44,66,88,100,120])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  preds = forward(X)\n",
    "  loss = loss_fn(Y, preds)\n",
    "  loss.backward()\n",
    "  grad = w.grad\n",
    "  with torch.no_grad(): #when we update weights we dont track gradients\n",
    "    w -= lr * w.grad\n",
    "  w.grad.zero_()\n",
    "  print(f\"Epoch {epoch+1} w(after)={w.item():.6f}\\n\")\n",
    "  print(f'Train Loss: {loss}')\n",
    "\n",
    "  with torch.inference_mode():\n",
    "    y_preds = forward(X_test)\n",
    "    test_loss = loss_fn(y_test, y_preds)\n",
    "    print(f'Y Predictions: {y_preds}')\n",
    "    print(f'Y Real: {y_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d034341",
   "metadata": {},
   "source": [
    "# Model, Loss, Optimizer\n",
    "\n",
    "A typical PyTorch pipeline is:\n",
    "\n",
    "1. Design/Replicate/Download a model\n",
    "2. Construct a Loss (how far we are from our predictions) and an optimizer (The algorithm we will use for backpropagation)\n",
    "3. Training Loop:\n",
    "  - Forward = compute predictions and loss\n",
    "  - Backward = compute gradients\n",
    "  - Update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8dff6763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearReg(\n",
       "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LinearReg(nn.Module):\n",
    "  def __init__(self, input_shape, output_shape):\n",
    "    super(LinearReg, self).__init__()\n",
    "    self.linear = nn.Linear(in_features=input_shape, out_features=output_shape)\n",
    "\n",
    "  def forward(self, X):\n",
    "    return self.linear(X)\n",
    "\n",
    "X = torch.tensor([[1], [2], [3], [4], [5], [6], [7], [8]], dtype=torch.float32).to('mps')\n",
    "Y = torch.tensor([[2], [4], [6], [8], [10], [12], [14], [16]], dtype=torch.float32).to('mps')\n",
    "\n",
    "n_examples, input_shape = X.shape\n",
    "out_shape = input_shape\n",
    "\n",
    "model = LinearReg(input_shape, out_shape).to('mps')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1ebc69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fc76c5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.002218024805188179\n",
      "W: 1.9810354709625244, b: 0.10321517288684845\n",
      "Loss: 0.0021165977232158184\n",
      "W: 1.9814743995666504, b: 0.10082679986953735\n",
      "Loss: 0.0020193203818053007\n",
      "W: 1.9819055795669556, b: 0.09848123043775558\n",
      "Loss: 0.0019260181579738855\n",
      "W: 1.9823287725448608, b: 0.09617793560028076\n",
      "Loss: 0.0018365615978837013\n",
      "W: 1.9827442169189453, b: 0.09391652047634125\n",
      "Loss: 0.0017507947050035\n",
      "W: 1.9831520318984985, b: 0.09169651567935944\n",
      "Loss: 0.0016686362214386463\n",
      "W: 1.98355233669281, b: 0.08951748162508011\n",
      "Loss: 0.0015898949932307005\n",
      "W: 1.9839452505111694, b: 0.08737894147634506\n",
      "Loss: 0.0015144911594688892\n",
      "W: 1.9843308925628662, b: 0.0852804034948349\n",
      "Loss: 0.0014422761742025614\n",
      "W: 1.9847091436386108, b: 0.08322139084339142\n",
      "Loss: 0.001373145030811429\n",
      "W: 1.9850802421569824, b: 0.08120144158601761\n",
      "Loss: 0.0013069873675704002\n",
      "W: 1.98544442653656, b: 0.07922004908323288\n",
      "Loss: 0.0012436870019882917\n",
      "W: 1.9858014583587646, b: 0.07727669924497604\n",
      "Loss: 0.0011831228621304035\n",
      "W: 1.9861515760421753, b: 0.07537095248699188\n",
      "Loss: 0.0011252203257754445\n",
      "W: 1.9864948987960815, b: 0.07350235432386398\n",
      "Loss: 0.0010698678670451045\n",
      "W: 1.986831545829773, b: 0.07167042046785355\n",
      "Loss: 0.0010169558227062225\n",
      "W: 1.98716139793396, b: 0.06987465918064117\n",
      "Loss: 0.0009663872187957168\n",
      "W: 1.9874848127365112, b: 0.06811462342739105\n",
      "Loss: 0.0009180938941426575\n",
      "W: 1.9878017902374268, b: 0.06638983637094498\n",
      "Loss: 0.0008719697361811996\n",
      "W: 1.9881123304367065, b: 0.06469979882240295\n",
      "Loss: 0.0008279305184260011\n",
      "W: 1.9884164333343506, b: 0.06304405629634857\n",
      "Loss: 0.0007859100005589426\n",
      "W: 1.9887144565582275, b: 0.06142218038439751\n",
      "Loss: 0.0007458007312379777\n",
      "W: 1.989006519317627, b: 0.059833671897649765\n",
      "Loss: 0.0007075391476973891\n",
      "W: 1.9892921447753906, b: 0.058278005570173264\n",
      "Loss: 0.0006710572051815689\n",
      "W: 1.9895721673965454, b: 0.05675479769706726\n",
      "Loss: 0.0006362693384289742\n",
      "W: 1.9898463487625122, b: 0.05526353046298027\n",
      "Loss: 0.0006031138473190367\n",
      "W: 1.9901145696640015, b: 0.05380368232727051\n",
      "Loss: 0.000571533280890435\n",
      "W: 1.9903768301010132, b: 0.05237488076090813\n",
      "Loss: 0.0005414403276517987\n",
      "W: 1.9906337261199951, b: 0.05097673833370209\n",
      "Loss: 0.0005127785843797028\n",
      "W: 1.9908851385116577, b: 0.04960877075791359\n",
      "Loss: 0.000485507509438321\n",
      "W: 1.9911309480667114, b: 0.04827049747109413\n",
      "Loss: 0.0004595394420903176\n",
      "W: 1.991371512413025, b: 0.04696148261427879\n",
      "Loss: 0.0004348448128439486\n",
      "W: 1.9916067123413086, b: 0.04568123817443848\n",
      "Loss: 0.0004113506875000894\n",
      "W: 1.991836667060852, b: 0.04442933201789856\n",
      "Loss: 0.00038901035441085696\n",
      "W: 1.9920616149902344, b: 0.043205324560403824\n",
      "Loss: 0.00036776892375200987\n",
      "W: 1.992281436920166, b: 0.042008787393569946\n",
      "Loss: 0.0003475928388070315\n",
      "W: 1.9924962520599365, b: 0.040839262306690216\n",
      "Loss: 0.0003284127451479435\n",
      "W: 1.992706298828125, b: 0.03969632834196091\n",
      "Loss: 0.0003102062619291246\n",
      "W: 1.9929115772247314, b: 0.03857950493693352\n",
      "Loss: 0.0002929093025159091\n",
      "W: 1.9931120872497559, b: 0.037488341331481934\n",
      "Loss: 0.0002765036770142615\n",
      "W: 1.9933079481124878, b: 0.036422450095415115\n",
      "Loss: 0.00026093103224411607\n",
      "W: 1.9934991598129272, b: 0.035381417721509933\n",
      "Loss: 0.00024615752045065165\n",
      "W: 1.9936858415603638, b: 0.03436485305428505\n",
      "Loss: 0.0002321580977877602\n",
      "W: 1.9938682317733765, b: 0.03337233513593674\n",
      "Loss: 0.0002188739163102582\n",
      "W: 1.9940463304519653, b: 0.032403409481048584\n",
      "Loss: 0.0002062884741462767\n",
      "W: 1.9942201375961304, b: 0.03145766258239746\n",
      "Loss: 0.0001943699608091265\n",
      "W: 1.9943896532058716, b: 0.030534669756889343\n",
      "Loss: 0.00018308070139028132\n",
      "W: 1.994555115699768, b: 0.029634077101945877\n",
      "Loss: 0.0001723914174363017\n",
      "W: 1.9947166442871094, b: 0.028755459934473038\n",
      "Loss: 0.00016227125888690352\n",
      "W: 1.9948742389678955, b: 0.027898374944925308\n",
      "Loss: 0.0001526923879282549\n",
      "W: 1.995027780532837, b: 0.02706240862607956\n",
      "Loss: 0.00014363953960128129\n",
      "W: 1.9951773881912231, b: 0.026247229427099228\n",
      "Loss: 0.0001350819948129356\n",
      "W: 1.9953234195709229, b: 0.02545250579714775\n",
      "Loss: 0.0001269870699616149\n",
      "W: 1.9954657554626465, b: 0.024677837267518044\n",
      "Loss: 0.00011933996574953198\n",
      "W: 1.9956045150756836, b: 0.02392282336950302\n",
      "Loss: 0.00011211285891477019\n",
      "W: 1.9957396984100342, b: 0.0231870599091053\n",
      "Loss: 0.00010529205610509962\n",
      "W: 1.9958714246749878, b: 0.022470172494649887\n",
      "Loss: 9.885218605631962e-05\n",
      "W: 1.9959996938705444, b: 0.02177179977297783\n",
      "Loss: 9.277513163397089e-05\n",
      "W: 1.9961247444152832, b: 0.021091612055897713\n",
      "Loss: 8.704297943040729e-05\n",
      "W: 1.996246337890625, b: 0.020429223775863647\n",
      "Loss: 8.163669554051012e-05\n",
      "W: 1.9963648319244385, b: 0.019784295931458473\n",
      "Loss: 7.65400764066726e-05\n",
      "W: 1.9964802265167236, b: 0.019156478345394135\n",
      "Loss: 7.173579797381535e-05\n",
      "W: 1.9965925216674805, b: 0.01854540966451168\n",
      "Loss: 6.721323006786406e-05\n",
      "W: 1.996701955795288, b: 0.017950698733329773\n",
      "Loss: 6.295005732681602e-05\n",
      "W: 1.9968082904815674, b: 0.017371976748108864\n",
      "Loss: 5.893593333894387e-05\n",
      "W: 1.9969117641448975, b: 0.01680891402065754\n",
      "Loss: 5.5162519856821746e-05\n",
      "W: 1.9970122575759888, b: 0.0162612646818161\n",
      "Loss: 5.16116815560963e-05\n",
      "W: 1.9971100091934204, b: 0.015728723257780075\n",
      "Loss: 4.8272271669702604e-05\n",
      "W: 1.997205138206482, b: 0.015210981480777264\n",
      "Loss: 4.513033854891546e-05\n",
      "W: 1.9972976446151733, b: 0.014707706868648529\n",
      "Loss: 4.217848618282005e-05\n",
      "W: 1.9973875284194946, b: 0.01421855017542839\n",
      "Loss: 3.940769238397479e-05\n",
      "W: 1.9974749088287354, b: 0.01374316867440939\n",
      "Loss: 3.680495865410194e-05\n",
      "W: 1.997559666633606, b: 0.013281254097819328\n",
      "Loss: 3.436233237152919e-05\n",
      "W: 1.997642159461975, b: 0.012832574546337128\n",
      "Loss: 3.2068601285573095e-05\n",
      "W: 1.9977222681045532, b: 0.012396769598126411\n",
      "Loss: 2.9916562198195606e-05\n",
      "W: 1.9978001117706299, b: 0.011973532848060131\n",
      "Loss: 2.7899477572645992e-05\n",
      "W: 1.9978755712509155, b: 0.011562570929527283\n",
      "Loss: 2.6009289285866544e-05\n",
      "W: 1.9979488849639893, b: 0.011163651943206787\n",
      "Loss: 2.4237724574049935e-05\n",
      "W: 1.9980199337005615, b: 0.010776503011584282\n",
      "Loss: 2.2577800336875953e-05\n",
      "W: 1.9980889558792114, b: 0.01040084008127451\n",
      "Loss: 2.102301732520573e-05\n",
      "W: 1.998155951499939, b: 0.010036380961537361\n",
      "Loss: 1.956984488060698e-05\n",
      "W: 1.9982209205627441, b: 0.00968286395072937\n",
      "Loss: 1.820889701775741e-05\n",
      "W: 1.998283863067627, b: 0.009340022690594196\n",
      "Loss: 1.6935828170971945e-05\n",
      "W: 1.9983450174331665, b: 0.00900760293006897\n",
      "Loss: 1.5745967175462283e-05\n",
      "W: 1.9984041452407837, b: 0.008685333654284477\n",
      "Loss: 1.4634949366154615e-05\n",
      "W: 1.9984616041183472, b: 0.008372967131435871\n",
      "Loss: 1.3596051758213434e-05\n",
      "W: 1.9985171556472778, b: 0.00807026494294405\n",
      "Loss: 1.2627378055185545e-05\n",
      "W: 1.9985711574554443, b: 0.007776990067213774\n",
      "Loss: 1.1721474947989918e-05\n",
      "W: 1.998623251914978, b: 0.007492890115827322\n",
      "Loss: 1.087706368707586e-05\n",
      "W: 1.9986737966537476, b: 0.007217750884592533\n",
      "Loss: 1.008867911878042e-05\n",
      "W: 1.998722791671753, b: 0.006951328832656145\n",
      "Loss: 9.355115253129043e-06\n",
      "W: 1.9987701177597046, b: 0.006693401839584112\n",
      "Loss: 8.669989256304689e-06\n",
      "W: 1.9988160133361816, b: 0.006443762220442295\n",
      "Loss: 8.033034646359738e-06\n",
      "W: 1.998860478401184, b: 0.006202173884958029\n",
      "Loss: 7.439256478392053e-06\n",
      "W: 1.9989033937454224, b: 0.00596842123195529\n",
      "Loss: 6.8857652877341025e-06\n",
      "W: 1.998944878578186, b: 0.005742321722209454\n",
      "Loss: 6.372058578563156e-06\n",
      "W: 1.9989850521087646, b: 0.005523657891899347\n",
      "Loss: 5.8934997468895745e-06\n",
      "W: 1.9990239143371582, b: 0.005312224850058556\n",
      "Loss: 5.44925296708243e-06\n",
      "W: 1.9990614652633667, b: 0.005107808858156204\n",
      "Loss: 5.035966751165688e-06\n",
      "W: 1.9990978240966797, b: 0.004910226911306381\n"
     ]
    }
   ],
   "source": [
    "# setup loss, and the learning rate with an optimizer\n",
    "# Run the training loop\n",
    "x_test = torch.tensor([[5]])\n",
    "y_test = torch.tensor([[10]])\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  model.train()\n",
    "\n",
    "  preds = model(X)\n",
    "  loss = loss_fn(preds, Y)\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  if (epoch % 10) == 0:\n",
    "    print(f'Loss: {loss}')\n",
    "    w, b = model.parameters()\n",
    "    print(f'W: {w.item()}, b: {b.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2959d35",
   "metadata": {},
   "source": [
    "Recall our initial linear equation: y = wx:\n",
    "\n",
    "$$\n",
    "y=2x\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "da6fa12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[21.9952],\n",
       "        [43.9856],\n",
       "        [87.9664]], device='mps:0', grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = torch.tensor([[11],[22],[44]], dtype=torch.float32).to('mps')\n",
    "Y_test = torch.tensor([[22],[44],[88]], dtype=torch.float32).to('mps')\n",
    "model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "777c942e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.axhline(y=0, color='k')\n",
    "plt.axvline(x=0, color='k')\n",
    "plt.plot(X.to('cpu'), Y.to('cpu'))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a008283",
   "metadata": {},
   "source": [
    "# First Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8dab4b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "1c03d2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup hyperparameters\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc6fab5",
   "metadata": {},
   "source": [
    "Load Datasets and Data Loaders from ready made datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2b2df3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset MNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: ./data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: ToTensor(),\n",
       " Dataset MNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ./data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: ToTensor())"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(\n",
    "  root='./data',\n",
    "  train=True,\n",
    "  transform=transforms.ToTensor(),\n",
    "  download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "  root='./data',\n",
    "  train=False,\n",
    "  transform=transforms.ToTensor(),\n",
    ")\n",
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "1901785e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x116d6e840>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x117154380>)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  dataset=train_dataset,\n",
    "  batch_size=batch_size,\n",
    "  shuffle=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  dataset=test_dataset,\n",
    "  batch_size=batch_size,\n",
    "  shuffle=False\n",
    ")\n",
    "\n",
    "train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "766cee64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = iter(train_loader)\n",
    "example_data, example_targets = next(examples)\n",
    "example_data.shape, example_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4b909c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 1, 1, 9, 2, 3, 4, 7, 5, 0, 9, 6, 6, 3, 3, 8, 4, 2, 5, 2, 2, 8, 8, 2,\n",
       "        8, 1, 6, 7, 4, 3, 3, 8])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "8a587628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "de3e1e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming batch_size=32, display first 9 images in a 3x3 grid\n",
    "num_images = 6\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(10, 10))\n",
    "\n",
    "for i in range(num_images):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    # Squeeze to remove channel dim (1, 28, 28) -> (28, 28)\n",
    "    img = example_data[i].squeeze().cpu().numpy()\n",
    "    axes[row, col].imshow(img, cmap='gray')\n",
    "    axes[row, col].set_title(f'Label: {example_targets[i].item()}')\n",
    "    axes[row, col].axis('off')  # Hide axes for cleaner look\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "0e356eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear): Linear(in_features=784, out_features=300, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (output): Linear(in_features=300, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a neural net for classification of images\n",
    "# we have an image of 28x28 and we need to flatten this and give it to a network\n",
    "# 28x28 => 784 1D tensor\n",
    "# Input layer = shape 784 (and we have 32 in each batch) so input shape will be (32,784)\n",
    "# Second layer is linear then relu then linear (with output shape 10 -> number of classes)\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "  def __init__(self, input_shape=784, hidden_dim=300, output_shape=10):\n",
    "    super(NeuralNet, self).__init__()\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.linear = nn.Linear(in_features=input_shape, out_features=hidden_dim)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.output = nn.Linear(in_features=hidden_dim, out_features=output_shape)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.flatten(x)\n",
    "    z = self.linear(x)\n",
    "    z = self.relu(z)\n",
    "    return self.output(z)\n",
    "  \n",
    "nn_model = NeuralNet().to('mps')\n",
    "nn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b5b097",
   "metadata": {},
   "source": [
    "Let's move our data to device and test our model with one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "62b87830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]], device='mps:0'),\n",
       " tensor([5, 1, 1, 9, 2, 3, 4, 7, 5, 0, 9, 6, 6, 3, 3, 8, 4, 2, 5, 2, 2, 8, 8, 2,\n",
       "         8, 1, 6, 7, 4, 3, 3, 8], device='mps:0'))"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data.to('mps'), example_targets.to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "9d486ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(nn_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "c11b9b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6666666666666666}"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "accuracy_fn = evaluate.load('accuracy')\n",
    "accuracy_fn.compute(references=[1,2,3], predictions=[1,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "5aade5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "acc_fn = evaluate.load('accuracy')\n",
    "def accuracy_fn(y_preds, y_true):\n",
    "  return acc_fn.compute(references=y_preds, predictions=y_true)['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "2a99aa44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.softmax(torch.tensor([4,2,3], dtype=torch.float32), dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "c7ca0487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "313"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "9cee4f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Avg Loss: 0.8588\n",
      "Test loss: 0.40313430082874174, Test accuracy: 0.8950678913738019\n",
      "Epoch: 1, Avg Loss: 0.3707\n",
      "Test loss: 0.3207221159610314, Test accuracy: 0.9092452076677316\n",
      "Epoch: 2, Avg Loss: 0.3167\n",
      "Test loss: 0.2873072275481285, Test accuracy: 0.9195287539936102\n",
      "Epoch: 3, Avg Loss: 0.2858\n",
      "Test loss: 0.2622605818368423, Test accuracy: 0.9259185303514377\n",
      "Epoch: 4, Avg Loss: 0.2621\n",
      "Test loss: 0.243568660637822, Test accuracy: 0.9293130990415336\n",
      "Epoch: 5, Avg Loss: 0.2428\n",
      "Test loss: 0.2274282820754872, Test accuracy: 0.93560303514377\n",
      "Epoch: 6, Avg Loss: 0.2259\n",
      "Test loss: 0.21360779705698402, Test accuracy: 0.9379992012779552\n",
      "Epoch: 7, Avg Loss: 0.2111\n",
      "Test loss: 0.19960592369200847, Test accuracy: 0.9427915335463258\n",
      "Epoch: 8, Avg Loss: 0.1978\n",
      "Test loss: 0.18925779527231765, Test accuracy: 0.9456869009584664\n",
      "Epoch: 9, Avg Loss: 0.1863\n",
      "Test loss: 0.17781065857579437, Test accuracy: 0.9487819488817891\n",
      "Epoch: 10, Avg Loss: 0.1753\n",
      "Test loss: 0.16916981382747762, Test accuracy: 0.9512779552715654\n",
      "Epoch: 11, Avg Loss: 0.1658\n",
      "Test loss: 0.16117184059605144, Test accuracy: 0.9518769968051118\n",
      "Epoch: 12, Avg Loss: 0.1567\n",
      "Test loss: 0.15521344178975127, Test accuracy: 0.9545726837060703\n",
      "Epoch: 13, Avg Loss: 0.1487\n",
      "Test loss: 0.1474235352023115, Test accuracy: 0.9571685303514377\n",
      "Epoch: 14, Avg Loss: 0.1413\n",
      "Test loss: 0.14071994049016373, Test accuracy: 0.9587659744408946\n",
      "Epoch: 15, Avg Loss: 0.1348\n",
      "Test loss: 0.1356917957808025, Test accuracy: 0.9603634185303515\n",
      "Epoch: 16, Avg Loss: 0.1284\n",
      "Test loss: 0.12979369590872714, Test accuracy: 0.9628594249201278\n",
      "Epoch: 17, Avg Loss: 0.1227\n",
      "Test loss: 0.1254276354074145, Test accuracy: 0.9630591054313099\n",
      "Epoch: 18, Avg Loss: 0.1175\n",
      "Test loss: 0.12062729407360735, Test accuracy: 0.9648562300319489\n",
      "Epoch: 19, Avg Loss: 0.1124\n",
      "Test loss: 0.11833237645925936, Test accuracy: 0.9658546325878594\n",
      "Epoch: 20, Avg Loss: 0.1079\n",
      "Test loss: 0.11377035479095524, Test accuracy: 0.9665535143769968\n",
      "Epoch: 21, Avg Loss: 0.1038\n",
      "Test loss: 0.1107961834689525, Test accuracy: 0.9684504792332268\n",
      "Epoch: 22, Avg Loss: 0.0998\n",
      "Test loss: 0.10790409759942668, Test accuracy: 0.9699480830670927\n",
      "Epoch: 23, Avg Loss: 0.0963\n",
      "Test loss: 0.10441374154605221, Test accuracy: 0.9698482428115016\n",
      "Epoch: 24, Avg Loss: 0.0927\n",
      "Test loss: 0.1011319437674946, Test accuracy: 0.9709464856230032\n"
     ]
    }
   ],
   "source": [
    "epochs = 25 \n",
    "\n",
    "for epoch in range(epochs):\n",
    "  nn_model.train() \n",
    "  epoch_loss = 0.0\n",
    "  num_batches = 0\n",
    "  \n",
    "  for step, (X, y) in enumerate(train_loader):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    preds = nn_model(X)\n",
    "    loss = loss_fn(preds, y)\n",
    "    \n",
    "    loss.backward()  # Compute gradients\n",
    "    optimizer.step()  # Update weights\n",
    "    optimizer.zero_grad()  # Zero gradients\n",
    "\n",
    "    epoch_loss += loss.item()  # Accumulate loss\n",
    "    num_batches += 1\n",
    "  \n",
    "  train_avg_loss = epoch_loss / num_batches  # Average loss\n",
    "  print(f'Epoch: {epoch}, Avg Loss: {train_avg_loss:.4f}')\n",
    "  test_acc = 0\n",
    "  test_loss = 0\n",
    "  with torch.inference_mode():\n",
    "    model.eval()\n",
    "    for X, y in test_loader:\n",
    "      X, y = X.to(device), y.to(device)\n",
    "      preds = nn_model(X)\n",
    "      test_loss += loss_fn(preds, y).item()\n",
    "      pred_classes = torch.argmax(torch.softmax(preds, dim=1), dim=1)\n",
    "      test_acc += accuracy_fn(pred_classes, y)\n",
    "\n",
    "    test_avg_acc = test_acc / len(test_loader)\n",
    "    test_avg_loss = test_loss / len(test_loader)\n",
    "    print(f'Test loss: {test_avg_loss}, Test accuracy: {test_avg_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc683636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
