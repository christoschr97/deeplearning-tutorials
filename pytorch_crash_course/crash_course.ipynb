{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af29ce98",
   "metadata": {},
   "source": [
    "# PyTorch Crash Course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d5a7b5",
   "metadata": {},
   "source": [
    "## 5 Chapters\n",
    "1. Introduction to Tensors  \n",
    "  - Tensor Operations: Create, Numpy, GPU Support\n",
    "2. Autograd: Automatic Differentiation of PyTorch  \n",
    "  - Linear Regression Example\n",
    "3. Training Loop with: Model, Loss, Optimizer  \n",
    "  - A Typical PyTorch Workflow / training pipeline\n",
    "4. Neural Network  \n",
    "  - Also: GPU/Mps, DataLoader, Transforms & Evaluation\n",
    "5. Convolutional Neural Network (CNN)  \n",
    "  - Also: Save & Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea253595",
   "metadata": {},
   "source": [
    "# 1. Introduction to Tensors\n",
    "\n",
    "Everything in Pytorch is a tensor. Tensor is the basic datastructure in PyTorch that extends numpy. \n",
    "\n",
    "In theory, tensor is a multi-dimensional matrix containing elements of the same data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c668033a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty(5): tensor([0., 0., 0., 0., 0.]) with shape torch.Size([5])\n",
      "empty(2,3): tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) with shape: torch.Size([2, 3])\n",
      "ones(1): tensor([1.]) with shape: torch.Size([1])\n",
      "ones(1,2): tensor([[1., 1.]]) with shape: torch.Size([1, 2])\n",
      "zeros(2): tensor([0., 0.]) with shape: torch.Size([2])\n",
      "zeros(2, 2): tensor([[0., 0.],\n",
      "        [0., 0.]]) with shape: torch.Size([2, 2])\n",
      "rand(5): tensor([0.6733, 0.4980, 0.4894, 0.5151, 0.1446]) with shape: torch.Size([5])\n",
      "rand(5,5): tensor([[0.8415, 0.5387, 0.5452, 0.6928, 0.3202],\n",
      "        [0.7853, 0.2013, 0.9171, 0.4358, 0.1147],\n",
      "        [0.9142, 0.1029, 0.1442, 0.8652, 0.0256],\n",
      "        [0.5981, 0.9496, 0.9197, 0.6694, 0.3403],\n",
      "        [0.4247, 0.6171, 0.0515, 0.8784, 0.1009]]) with shape: torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.empty(5)\n",
    "print(f'empty(5): {x} with shape {x.shape}')\n",
    "x = torch.empty(2,3)\n",
    "print(f'empty(2,3): {x} with shape: {x.shape}')\n",
    "x = torch.ones(1)\n",
    "print(f'ones(1): {x} with shape: {x.shape}')\n",
    "x = torch.ones(1,2)\n",
    "print(f'ones(1,2): {x} with shape: {x.shape}')\n",
    "x = torch.zeros(2)\n",
    "print(f'zeros(2): {x} with shape: {x.shape}')\n",
    "x = torch.zeros(2,2)\n",
    "print(f'zeros(2, 2): {x} with shape: {x.shape}')\n",
    "x = torch.rand(5)\n",
    "print(f'rand(5): {x} with shape: {x.shape}')\n",
    "x = torch.rand(5,5)\n",
    "print(f'rand(5,5): {x} with shape: {x.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a3d5c6",
   "metadata": {},
   "source": [
    "We can check the size of the tensor using `.size()` or the shape of a tensor using `.shape()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df8d6daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([5, 5])\n",
      "Shape: torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(f'Size: {x.size()}') # specific dimension .size(0)\n",
    "print(f'Shape: {x.shape}') # specific dimension .shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f8474ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensor tensor([[0.8415, 0.5387, 0.5452, 0.6928, 0.3202],\n",
      "        [0.7853, 0.2013, 0.9171, 0.4358, 0.1147],\n",
      "        [0.9142, 0.1029, 0.1442, 0.8652, 0.0256],\n",
      "        [0.5981, 0.9496, 0.9197, 0.6694, 0.3403],\n",
      "        [0.4247, 0.6171, 0.0515, 0.8784, 0.1009]]) has dtype: torch.float32\n",
      "The tensor tensor([[0.4570, 0.9282, 0.7173, 0.4727, 0.1353],\n",
      "        [0.1509, 0.6665, 0.3784, 0.6333, 0.7949],\n",
      "        [0.0498, 0.8657, 0.3813, 0.8369, 0.3643],\n",
      "        [0.0381, 0.1670, 0.9619, 0.4648, 0.5718],\n",
      "        [0.0898, 0.2207, 0.0068, 0.7817, 0.5752]], dtype=torch.float16) has dtype: torch.float16\n"
     ]
    }
   ],
   "source": [
    "# check the data type of a tensor using:\n",
    "print(f'The tensor {x} has dtype: {x.dtype}')\n",
    "\n",
    "# To define a tensor with different dtype we should define it upon creation\n",
    "x = torch.rand(5,5, dtype=torch.float16)\n",
    "print(f'The tensor {x} has dtype: {x.dtype}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6018ab3c",
   "metadata": {},
   "source": [
    "We can also construct a tensor from a Python List or a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da4d86f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np_array = np.array([1,2,3])\n",
    "x = torch.tensor(np_array)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b2c1783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_list = [1,2,3]\n",
    "x = torch.tensor(py_list)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1e09b6",
   "metadata": {},
   "source": [
    "Another one important thing to know is that a tensor has an argument `requires_grad` which is by default set to `False`. If we set this to true, then python will track `gradients` for that numpy array. \n",
    "\n",
    "In a simple way, it will tell pytorch that it will need to calculate gradients for this tensor. We need this later in the optimization step, and we use it for all variables in our model that we want to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0760287c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3], requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fab5502",
   "metadata": {},
   "source": [
    "## 1.2 Operations on tensors\n",
    "\n",
    "This is simliar to numpy arrays. All the operations unless specified are element-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5902b3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.]]),\n",
       " tensor([[0.9356, 0.8502],\n",
       "         [0.8692, 0.1311]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2,2)\n",
    "y = torch.rand(2,2)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca50c5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9356, 1.8502],\n",
       "        [1.8692, 1.1311]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Elementwise addition\n",
    "z = x + y\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "457202af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subtraction: tensor([[0.0644, 0.1498],\n",
      "        [0.1308, 0.8689]])\n",
      "subtraction: tensor([[0.9356, 0.8502],\n",
      "        [0.8692, 0.1311]])\n",
      "subtraction: tensor([[1.0688, 1.1762],\n",
      "        [1.1505, 7.6269]])\n"
     ]
    }
   ],
   "source": [
    "# Elementwise subtraction, multiplication and division\n",
    "z = x - y\n",
    "print(f'subtraction: {z}')\n",
    "z = x * y\n",
    "print(f'subtraction: {z}')\n",
    "z = x / y\n",
    "print(f'subtraction: {z}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d480327",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991e37ec",
   "metadata": {},
   "source": [
    "Indexing and slicing on torch tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "decbc6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3224, 0.0053],\n",
       "         [0.7883, 0.4331],\n",
       "         [0.2507, 0.8969]],\n",
       "\n",
       "        [[0.2828, 0.5628],\n",
       "         [0.0871, 0.4265],\n",
       "         [0.2292, 0.5341]],\n",
       "\n",
       "        [[0.4714, 0.1922],\n",
       "         [0.1939, 0.3335],\n",
       "         [0.3064, 0.5884]],\n",
       "\n",
       "        [[0.9674, 0.1169],\n",
       "         [0.5641, 0.1002],\n",
       "         [0.3880, 0.6121]],\n",
       "\n",
       "        [[0.6654, 0.0183],\n",
       "         [0.9934, 0.4897],\n",
       "         [0.2130, 0.9235]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5,3,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f2ca86a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7883, 0.4331],\n",
       "        [0.0871, 0.4265],\n",
       "        [0.1939, 0.3335],\n",
       "        [0.5641, 0.1002],\n",
       "        [0.9934, 0.4897]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071d941e",
   "metadata": {},
   "source": [
    "`.item()` converts a single number tensor into scalar. If it has more than 1 element it will break."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c7fd885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype: 0.4265291690826416 of tensor tensor([[[0.3224, 0.0053],\n",
      "         [0.7883, 0.4331],\n",
      "         [0.2507, 0.8969]],\n",
      "\n",
      "        [[0.2828, 0.5628],\n",
      "         [0.0871, 0.4265],\n",
      "         [0.2292, 0.5341]],\n",
      "\n",
      "        [[0.4714, 0.1922],\n",
      "         [0.1939, 0.3335],\n",
      "         [0.3064, 0.5884]],\n",
      "\n",
      "        [[0.9674, 0.1169],\n",
      "         [0.5641, 0.1002],\n",
      "         [0.3880, 0.6121]],\n",
      "\n",
      "        [[0.6654, 0.0183],\n",
      "         [0.9934, 0.4897],\n",
      "         [0.2130, 0.9235]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4265291690826416, float)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wihtout item it is a tensor:\n",
    "print(f'dtype: {x[1,1,1]} of tensor {x}')\n",
    "x[1,1,1].item(), type(x[1,1,1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d24aec92",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 2 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: a Tensor with 2 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "x[1,1].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f54333",
   "metadata": {},
   "source": [
    "Reshaping a tensor:\n",
    "- Can be done either with `view()` either with `.reshape()`\n",
    "\n",
    "The main differences between torch.view() and torch.reshape() are: Memory and Storage\n",
    "\n",
    "`view()`:\n",
    "- Creates a view of the original tensor (shares the same memory)\n",
    "- Does not copy data - just changes how the tensor is interpreted\n",
    "- Requires the tensor to be contiguous in memory\n",
    "- Will fail if the tensor is not contiguous\n",
    "\n",
    "`reshape()`:\n",
    "- Can return either a view OR a copy depending on the tensor's memory layout\n",
    "- Works with both contiguous and non-contiguous tensors\n",
    "- May create a copy if the tensor is not contiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a4bf0393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7304, 0.0771, 0.7171, 0.3782, 0.4496, 0.0919, 0.6032, 0.2691, 0.3198,\n",
       "         0.6993, 0.6584, 0.2737, 0.7963, 0.5940, 0.6395, 0.0698]),\n",
       " torch.Size([16]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(4,4)\n",
    "y = x.view(16)\n",
    "y, x.view(16).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "508482f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7304, 0.0771, 0.7171, 0.3782, 0.4496, 0.0919, 0.6032, 0.2691],\n",
       "        [0.3198, 0.6993, 0.6584, 0.2737, 0.7963, 0.5940, 0.6395, 0.0698]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(-1, 8) # will fill the dimensions required to match the shape of the original tensor\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0965337b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x storage address: 5409951936\n",
      "z storage address: 5409951936\n"
     ]
    }
   ],
   "source": [
    "print(f\"x storage address: {x.storage().data_ptr()}\")\n",
    "print(f\"z storage address: {z.storage().data_ptr()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f03c57",
   "metadata": {},
   "source": [
    "Convert a tensor to a numpy array or vice versa.\n",
    "\n",
    "If tensors are on the CPU, converting them to numpy will share the same memory location (so one change affect the both the tensor and the numpy array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5478269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5,2)\n",
    "np_x = x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "733b7597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4628, 1.5563],\n",
      "        [1.7423, 1.0034],\n",
      "        [1.6913, 1.0113],\n",
      "        [1.0346, 1.1374],\n",
      "        [1.0591, 1.0742]])\n",
      "[[1.462799  1.5562607]\n",
      " [1.7423112 1.003419 ]\n",
      " [1.691334  1.0113358]\n",
      " [1.0345505 1.137443 ]\n",
      " [1.0590763 1.0742233]]\n"
     ]
    }
   ],
   "source": [
    "x.add_(1)\n",
    "print(x)\n",
    "print(np_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8443ee6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True],\n",
       "        [True, True]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x == np_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ca1f23",
   "metadata": {},
   "source": [
    "On the other hand, if we create a torch from numpy will still share the same memory address, unless we specify explicitly a new tensor from that numpy array with the traditional way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ee2582c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: torch.from_numpy() - SHARES memory\n",
    "tensor1 = torch.from_numpy(np_array)\n",
    "\n",
    "# Method 2: torch.tensor() - COPIES data (creates new memory)\n",
    "tensor2 = torch.tensor(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3092496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
